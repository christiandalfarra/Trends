Use GPU: 0 for training
Initializing the contect with given words: [a_photo_of_a]
Initial context: "a photo of a"
Number of context words (tokens): 4
=> Model created: visual backbone RN50
=> Using native Torch AMP. Training in mixed precision.
evaluating: A
Riduzione dataset da 7500 a 800 immagini...
number of test samples: 800
tpt_classification.py:149: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(init_scale=1000)
tpt_classification.py:62: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
tpt_classification.py:291: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Test: [199/800]	Time  0.173 ( 0.179)	Acc@1   0.00 ( 24.50)	Acc@5 100.00 ( 61.50)
Test: [399/800]	Time  0.172 ( 0.176)	Acc@1   0.00 ( 23.00)	Acc@5   0.00 ( 58.00)
Test: [599/800]	Time  0.172 ( 0.175)	Acc@1   0.00 ( 23.17)	Acc@5   0.00 ( 56.83)
Test: [799/800]	Time  0.170 ( 0.174)	Acc@1   0.00 ( 24.12)	Acc@5 100.00 ( 54.88)
 *  Acc@1 24.125 Acc@5 54.875
=> Acc. on testset [A]: @1 24.125/ @5 54.875
======== Result Summary ========
params: nstep	lr	bs
params: 1	0.0025	16
		 [set_id] 		 Top-1 acc. 		 Top-5 acc.
A	

24.12	

