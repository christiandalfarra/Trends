Use GPU: 0 for training
  0%|                                               | 0.00/244M [00:00<?, ?iB/s]  5%|██                                     | 12.9M/244M [00:00<00:01, 136MiB/s] 11%|████▏                                  | 25.9M/244M [00:00<00:01, 130MiB/s] 16%|██████▍                                | 40.1M/244M [00:00<00:01, 138MiB/s] 22%|████████▌                              | 53.2M/244M [00:00<00:01, 128MiB/s] 27%|██████████▍                            | 65.5M/244M [00:00<00:01, 124MiB/s] 32%|████████████▍                          | 78.2M/244M [00:00<00:01, 127MiB/s] 38%|██████████████▊                        | 92.5M/244M [00:00<00:01, 134MiB/s] 43%|█████████████████▎                      | 105M/244M [00:00<00:01, 123MiB/s] 49%|███████████████████▊                    | 121M/244M [00:00<00:00, 133MiB/s] 56%|██████████████████████▎                 | 136M/244M [00:01<00:00, 143MiB/s] 62%|████████████████████████▌               | 150M/244M [00:01<00:00, 140MiB/s] 67%|██████████████████████████▊             | 164M/244M [00:01<00:00, 137MiB/s] 72%|████████████████████████████▉           | 177M/244M [00:01<00:00, 120MiB/s] 77%|██████████████████████████████▉         | 189M/244M [00:01<00:00, 109MiB/s] 82%|████████████████████████████████▋       | 199M/244M [00:01<00:00, 109MiB/s] 87%|██████████████████████████████████▉     | 213M/244M [00:01<00:00, 117MiB/s] 92%|████████████████████████████████████▊   | 224M/244M [00:01<00:00, 117MiB/s] 97%|██████████████████████████████████████▋ | 236M/244M [00:01<00:00, 115MiB/s]100%|████████████████████████████████████████| 244M/244M [00:02<00:00, 125MiB/s]Random initialization: initializing a generic context
Initial context: "X X X X"
Number of context words (tokens): 4
=> Model created: visual backbone RN50
=> Using native Torch AMP. Training in mixed precision.
evaluating: A
number of test samples: 7500

tpt_classification.py:149: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(init_scale=1000)
tpt_classification.py:62: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
tpt_classification.py:290: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Test: [199/469]	Time  0.169 ( 0.176)	Acc@1  31.25 ( 17.62)	Acc@5  50.00 ( 42.66)
Test: [399/469]	Time  0.171 ( 0.173)	Acc@1  25.00 ( 17.89)	Acc@5  37.50 ( 43.34)
 *  Acc@1 17.787 Acc@5 43.227
=> Acc. on testset [A]: @1 17.786666870117188/ @5 43.22666549682617
======== Result Summary ========
params: nstep	lr	bs
params: 1	0.005	16
		 [set_id] 		 Top-1 acc. 		 Top-5 acc.
A	

17.79	

