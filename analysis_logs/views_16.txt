Use GPU: 0 for training
Initializing the contect with given words: [a photo of a ]
Initial context: "a photo of a "
Number of context words (tokens): 5
=> Model created: visual backbone RN50
=> Using native Torch AMP. Training in mixed precision.
evaluating: A
number of test samples: 7500
tpt_classification.py:149: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(init_scale=1000)
tpt_classification.py:62: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
tpt_classification.py:290: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Test: [199/469]	Time  0.176 ( 0.175)	Acc@1   6.25 ( 13.28)	Acc@5  12.50 ( 27.22)
Test: [399/469]	Time  0.168 ( 0.172)	Acc@1   6.25 ( 13.16)	Acc@5  18.75 ( 27.05)
 *  Acc@1 13.107 Acc@5 27.000
=> Acc. on testset [A]: @1 13.106666564941406/ @5 27.0
======== Result Summary ========
params: nstep	lr	bs
params: 1	0.005	16
		 [set_id] 		 Top-1 acc. 		 Top-5 acc.
A	

13.11	

